---
title: srs_var_4
output:
  html_document:
    df_print: paged
---

Исходные данные:Набор данных Polish companies bankruptcy содержит сведения о банкротстве польских компаний через 4 года после наблюдения.
Сформулируем гипотезу о том, влияет ли на банкротство отношение чистой прибыли к общей стоимости активов, отношение задолженности к активам,  отношение собственных оборотных средств к общей стоимости активов,
отношение текущих активов к краткосрочной задолженности и отношение прибыли до выплаты процентов и налогов к общей сумме активов.
```{r first}
library('GGally') 
library('lmtest')
library('FNN')
library('mlbench')
library('boot')
library('ISLR')
library('MASS')
#загружаем данные 
polish <- read.csv('Polish_Comp_Bnkrp_2year_for_models.csv', 
                     header = T,
                     dec = ',',
                     sep = ';')
polish$class <- as.factor(polish$class)
reg.df <- polish
dim(reg.df)
head(reg.df)
str(reg.df)
summary(reg.df)

#стороим модель, избавляемся от незначимых переменных
model.1 <- glm(class ~ ., 
              data = reg.df, family = 'binomial')
summary(model.1)

model.2 <- glm(class ~ Attr1 + Attr2 + Attr3 + Attr7, 
               data = reg.df, family = 'binomial')
summary(model.2)
model.3 <- glm(class ~ Attr1 + Attr3 + Attr7, 
               data = reg.df, family = 'binomial')

summary(model.3)

#совместный график разброса переменных
ggp <- ggpairs(reg.df, 
               mapping = ggplot2::aes(color = class))
print(ggp, progress = F)

```
Лучшей моделью оказалась model.3.
На банкротство влияет отношение чистой прибыли к общей стоимости активов, отношение собственных оборотных средств к общей стоимости активов,отношение прибыли до выплаты процентов и налогов к общей сумме активов.
```{r second}
#k-кратная перекрёстная проверка
#оценим точность полиномиальных моделей
#вектор с ошибками по 5-кратной кросс-валидации
cv.err.k.fold <- rep(0, 5)
names(cv.err.k.fold) <- 1:5
# цикл по степеням полиномов
for (i in 1:5) {
  fit.glm <- glm(class~ poly(Attr1,i) + Attr3 + Attr7, data = reg.df,
                 family = 'binomial')
  cv.err.k.fold[i] <- cv.glm(reg.df, fit.glm,
                             K = 5)$delta[1]
}
# результат
cv.err.k.fold

cv.err.k.fold <- rep(0, 5)
names(cv.err.k.fold) <- 1:5
# цикл по степеням полиномов
for (i in 1:5) {
  fit.glm <- glm(class~ Attr1 + poly(Attr3,i) + Attr7, data = reg.df,
                 family = 'binomial')
  cv.err.k.fold[i] <- cv.glm(reg.df, fit.glm,
                             K = 5)$delta[1]
}
# результат
cv.err.k.fold

cv.err.k.fold <- rep(0, 5)
names(cv.err.k.fold) <- 1:5
# цикл по степеням полиномов
for (i in 1:5) {
  fit.glm <- glm(class~ Attr1 + Attr3 + poly(Attr7,i), data = reg.df,
                 family = 'binomial')
  cv.err.k.fold[i] <- cv.glm(reg.df, fit.glm,
                             K = 5)$delta[1]
}
# результат
cv.err.k.fold
```
Вторая модель самая лучшая, так как имеет наименьшую ошибку.


Для прогноза используем данные Polish_Comp_Bnkrp_2year_for_forecast.csv.
Построим модель LDA и матрицу неточностей.
ROC-кривая для LDA.
Построим график совместного изменения чувствительности и специфичности с изменением вероятности отсечения от 0 до 1 – ROC-кривую. Для примера возьмём модель LDA.
```{r third}
polish1 <- read.csv('Polish_Comp_Bnkrp_2year_for_forecast.csv', 
                   header = T,
                   dec = ',',
                   sep = ';')
df <- polish1
Факт <- reg.df$class
# прогноз: вероятности принадлежности классу '1' 
p.logit1 <- predict(model.3, df, type = 'response')
Прогноз1 <- factor(ifelse(p.logit1 > 0.5, 2, 1),
                  levels = c(1, 2),
                  labels = c('0', '1'))

p.logit <- predict(model.3, reg.df, type = 'response')
Прогноз <- factor(ifelse(p.logit > 0.5, 2, 1),
                  levels = c(1, 2),
                  labels = c('0', '1'))


######
#LDA
model.lda <- lda(class ~ Attr1 + Attr3 + Attr7, data = reg.df,
                 family = 'binomial')
model.lda

p.lda <- predict(model.lda, reg.df, type = 'response')
Прогноз <- factor(ifelse(p.lda$posterior[, '1'] > 0.5, 
                         2, 1),
                  levels = c(1, 2),
                  labels = c('0', '1'))

# матрица неточностей
conf.m <- table(Факт, Прогноз)
conf.m
#########

#ROC-кривая для LDA
x <- NULL    # для (1 - SPC)
y <- NULL    # для TPR

# заготовка под матрицу неточностей
tbl <- as.data.frame(matrix(rep(0, 4), 2, 2))
rownames(tbl) <- c('fact.0', 'fact.1')
colnames(tbl) <- c('predict.0', 'predict.1')

# вектор вероятностей для перебора
p.vector <- seq(0, 1, length = 501)

# цикл по вероятностям отсечения
for (p in p.vector) {
  # прогноз
  Прогноз <- factor(ifelse(p.lda$posterior[, '1'] > p, 
                          2, 1),
                    levels = c(1, 2),
                    labels = c('0', '1'))
  #Прогноз <- factor(ifelse(p.logit > 0.5,2,1),
                    #levels = c(1, 2),
                    #labels = c('0', '1'))
  # фрейм со сравнением факта и прогноза
  df.compare <- data.frame(Факт = Факт, Прогноз = Прогноз)
  
  # заполняем матрицу неточностей
  tbl[1, 1] <- nrow(df.compare[df.compare$Факт == '0' & df.compare$Прогноз == '0', ])
  tbl[2, 2] <- nrow(df.compare[df.compare$Факт == '1' & df.compare$Прогноз == '1', ])
  tbl[1, 2] <- nrow(df.compare[df.compare$Факт == '0' & df.compare$Прогноз == '1', ])
  tbl[2, 1] <- nrow(df.compare[df.compare$Факт == '1' & df.compare$Прогноз == '0', ])
  
  # считаем характеристики
  TPR <- tbl[2, 2] / sum(tbl[2, 2] + tbl[2, 1])
  y <- c(y, TPR)
  SPC <- tbl[1, 1] / sum(tbl[1, 1] + tbl[1, 2])
  x <- c(x, 1 - SPC)
}

# строим ROC-кривую
par(mar = c(5, 5, 1, 1))
# кривая
plot(x, y, type = 'l', col = 'blue', lwd = 3,
     xlab = '(1 - SPC)', ylab = 'TPR', 
     xlim = c(0, 1), ylim = c(0, 1))
# прямая случайного классификатора
abline(a = 0, b = 1, lty = 3, lwd = 2)
p.vector <- seq(0, 1, length = 501)
# точка для вероятности 0.5
points(x[p.vector == 0.5], y[p.vector == 0.5], pch = 16)
text(x[p.vector == 0.5], y[p.vector == 0.5], 'p = 0.5', pos = 4)
# точка для вероятности 0.2
points(x[p.vector == 0.2], y[p.vector == 0.2], pch = 16)
text(x[p.vector == 0.2], y[p.vector == 0.2], 'p = 0.2', pos = 4)
```
Видно, что изменение границы отсечения с 0.5 до 0.2 чувствительность модели не меняется. 